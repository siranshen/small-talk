import dedent from 'dedent'
import getResponseStream from '@/app/utils/openai'
import { NextRequest, NextResponse } from 'next/server'
import { GPTMessage } from '@/app/utils/chat-message'

export const runtime = 'edge'

// TODO: Perhaps best to provide a evaluation template/example for each language
const constructSystemPrompt = (language: string, evalLanguage: string, convo: string) => {
  return dedent`You are a professional ${evalLanguage} teacher.
  You are given user messages from a conversation with an AI, and your task is to evaluate the user's performance.

  ## Rules
  1. Overall evaluation should be provided in ${language}. You should still use ${evalLanguage} when citing user's message or giving specific suggestions.
  2. Evaluate user's messages one by one. For each message, analyze its grammar, vocabulary usage, and fluency.
  3. User's text may be generated by speech recognition, so you should ignore the punctuation mistakes.
  4. List all other mistakes you find, each followed by a citation of the original message and a suggestion.

  ## Messages
  ${convo}

  ## Evaluation
  `
}

export async function POST(request: NextRequest) {
  if (process.env.NODE_ENV === 'development') {
    await new Promise((resolve) => setTimeout(resolve, 1000))
    return new NextResponse('This is a dummy answer used in development mode. Uncomment this line to use the API.')
  }
  const { messages, language, evalLanguage } = await request.json()
  try {
    const stream = await getResponseStream(
      constructSystemPrompt(
        language,
        evalLanguage,
        messages
          .filter((msg: GPTMessage) => msg.role === 'user')
          .map((msg: GPTMessage) => `- ${msg.content}`)
          .join('\n')
      ),
      [],
      0,
      1000
    )
    return new NextResponse(stream)
  } catch (e) {
    console.log('Error calling OpenAI', e)
    return new NextResponse('Error calling OpenAI', { status: 500 })
  }
}
